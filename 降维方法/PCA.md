# 希望达成的目标

***

*   [x] 了解主成分分析基本原理与数学推导
*   [x] 在乳腺癌数据集上实践PCA

***

# 基本原理

***

## **目的**

*   **我们想做什么**：通过某种投影方法，在让高维度数据变成低维度数据的同时，减少因维度降低而带来的“信息损耗”。
*   **我们想达到的目标**：在降低维度的同时，减少信息损耗量。

## **关键数学推导**

### 从目的出发

既然要减少信息损耗量，我们需要首先度量信息损耗量。根据“最大方差理论”，方差越大，信息量也就越大。也就是说，如果我们要尽可能地保持样本特征的“信息量”，我们就相当于是选择使方差较大的方式投影。那么，怎样投影才会使得方差较大呢？



### 协方差矩阵的特征值与特征向量

我们可以通过求协方差矩阵的特征值与特征向量来达到这一点：

记有n个特征的第i个样本（假设共有N个样本)为：

```math
X^i = (x_1^i,x_2^i,...,x_n^i)^T
```

这N个样本投影到同一根直线（所以Y与i无关，这之后会用到），记这条直线的单位向量为：

```math
Y = (Y_1,Y_2,...,Y_n)^T
```

我们已经知道，向量与单位向量的外积代表向量的投影长度，那么下式便代表样本在投影直线上的长度：

```math
L = X^{i^T}·Y
```

如此一来，我们计算样本投影长度的方差如下，为了方便计算，通过去中心化处理使得长度均值为0：

```math
D = \frac{1}{N}\Sigma_i^N(L-\bar{L})^2=\frac{1}{N}\Sigma_i^NL^2=\frac{1}{N}\Sigma_i^NY^Tx^ix^{i^T}Y=Y^T(\Sigma_i^N\frac{1}{N}x^ix^{i^T})Y
```

记作：

```math
D=Y^TCY,DY=CY
```

此外，由于我们之前做了去中心化处理，如果把C写开来，不难发现它其实是协方差矩阵。也就是说，在投影过后，方差其实是协方差矩阵的特征值。这意味着，我们只要求协方差矩阵的特征值，就相当于是知道了方差的大小。而我们的Y，其实就相当于C的特征向量·。

## **步骤**

有了上述推导，我们马上可以写出步骤：

1.  去中心化，即让每个特征减去其均值；
2.  计算样本特征的协方差矩阵，及其特征值与对应的特征向量；
3.  将特征值按降序排序，选择前k个最大的特征值；
4.  将3中特征值与样本向量相乘，即可得到变换后的向量。

***

# PCA的实现

***

